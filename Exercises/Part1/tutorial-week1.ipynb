{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 1: Introduction to OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requirements for this tutorial\n",
    "! pip install opencv-python\n",
    "! pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you prefer, you can convert this notebook to a Python script by uncommenting the following command\n",
    "! pip install nbconvert\n",
    "! jupyter nbconvert --to script tutorial-week1.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "import itertools\n",
    "import os\n",
    "\n",
    "dataDir = './data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Images – read, write and display; ROIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "height: 380\n",
      "width: 308\n",
      "channels: 3\n"
     ]
    }
   ],
   "source": [
    "# Opening an image\n",
    "img = cv2.imread(os.path.join(dataDir, 'ml.jpg'))\n",
    "\n",
    "# Showing the image\n",
    "cv2.imshow(\"ml.jpg\", img)\n",
    "\n",
    "# Waiting for user to press a key to close the image\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Close the window after user pressed a key\n",
    "cv2.destroyWindow(\"ml.jpg\")\n",
    "\n",
    "# Check image size\n",
    "h, w, c = img.shape\n",
    "print(f'height: {h}')\n",
    "print(f'width: {w}')\n",
    "print(f'channels: {c}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving image in bmp format\n",
    "cv2.imwrite(os.path.join(dataDir, 'ml_new.bmp'), img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening an image\n",
    "img = cv2.imread(os.path.join(dataDir, 'ml.jpg'))\n",
    "\n",
    "# Showing the image\n",
    "cv2.imshow(\"ml.jpg\", img)\n",
    "\n",
    "# Create Color palette\n",
    "cv2.createTrackbar('R','ml.jpg',0,255, lambda *args: None)\n",
    "cv2.createTrackbar('G','ml.jpg',0,255, lambda *args: None)\n",
    "cv2.createTrackbar('B','ml.jpg',0,255, lambda *args: None)\n",
    "\n",
    "# Modify the RGB components of a selected pixel\n",
    "def changeRGB(event, x, y, flags, userdata):\n",
    "    b,g,r = img[y,x]\n",
    "    r_input = cv2.getTrackbarPos('R','ml.jpg')\n",
    "    g_input = cv2.getTrackbarPos('G','ml.jpg')\n",
    "    b_input = cv2.getTrackbarPos('B','ml.jpg')\n",
    "    rgb = f'{r}, {g}, {b}'\n",
    "    coordinates = f'{x}, {y}'\n",
    "    \n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        img[y,x] = r_input, g_input, b_input\n",
    "    \n",
    "    img_copy = img.copy()\n",
    "    cv2.putText(img_copy, coordinates, (0,375), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    cv2.putText(img_copy, rgb, (x,y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "    cv2.imshow(\"ml.jpg\", img_copy)\n",
    "    \n",
    "# Set the mouse handler\n",
    "cv2.setMouseCallback(\"ml.jpg\", changeRGB)\n",
    "\n",
    "# Waiting for user to press a key to close the image\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Close the window after user pressed a key\n",
    "cv2.destroyWindow(\"ml.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Opening an image\n",
    "img = cv2.imread(os.path.join(dataDir, 'ml.jpg'))\n",
    "\n",
    "# Select region of interest (ROI) in the image\n",
    "roi = cv2.selectROI(img)\n",
    "\n",
    "roi_cropped=img[int(roi[1]):int(roi[1]+roi[3]), int(roi[0]):int(roi[0]+roi[2])]\n",
    "\n",
    "# Close all windows after ROI selection\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Saving cropped region of interest (ROI)\n",
    "cv2.imwrite(os.path.join(dataDir, 'roi.jpg'), roi_cropped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Images – representation, grayscale and color, color spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a white image\n",
    "m = np.ones((100,200,1), np.uint8)\n",
    "\n",
    "# Change the intensity to 100\n",
    "m = m * 100\n",
    "\n",
    "# Draw diagonals with thickness of 5 px\n",
    "cv2.line(m, (0,0), (200,100), 255, 5)\n",
    "cv2.line(m, (200, 0), (0, 100), 255, 5)\n",
    "\n",
    "# Display the image\n",
    "cv2.imshow('Grayscale image with diagonals', m)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyWindow('Grayscale image with diagonals')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a white image\n",
    "m = np.ones((100,200,3), np.uint8)\n",
    "\n",
    "# Change the color to yellow\n",
    "m[:] = (0,255,255)\n",
    "\n",
    "# Draw diagonals with thickness of 5 px\n",
    "cv2.line(m, (0,0), (200,100), (0,0,255), 5)\n",
    "cv2.line(m, (200, 0), (0, 100), (255,0,0), 5)\n",
    "\n",
    "# Display the image\n",
    "cv2.imshow('Yellow image with diagonals', m)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyWindow('Yellow image with diagonals')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Opening an image\n",
    "img = cv2.imread(os.path.join(dataDir, 'ml.jpg'))\n",
    "\n",
    "# Convert the color image to grayscale\n",
    "grayscale = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Display the image\n",
    "cv2.imshow(\"Color image\", img)\n",
    "\n",
    "# Display the grayscale image\n",
    "cv2.imshow(\"Grayscale image\", grayscale)\n",
    "\n",
    "# Close all windows after user pressed a key\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Saving the grayscale image\n",
    "cv2.imwrite(os.path.join(dataDir, 'grayscale.jpg'), grayscale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Opening an image\n",
    "img = cv2.imread(os.path.join(dataDir, 'ml.jpg'))\n",
    "\n",
    "# Determine number of noisy pixels\n",
    "rows,cols,ch = img.shape\n",
    "num_pixels = rows * cols\n",
    "num_salt_pepper = int(np.ceil(0.1 * num_pixels))\n",
    "\n",
    "# Select the random noisy pixels\n",
    "rows_indexes = list(range(rows))\n",
    "cols_indexes = list(range(cols))\n",
    "combinations = list(itertools.product(rows_indexes, cols_indexes))\n",
    "indexes = random.sample(combinations, num_salt_pepper)\n",
    "\n",
    "# Apply the salt and pepper noise\n",
    "for i, coords in enumerate(indexes):\n",
    "    if i < num_salt_pepper/2:\n",
    "        img[coords] = (0, 0, 0)\n",
    "    else:\n",
    "        img[coords] = (255, 255, 255)\n",
    "\n",
    "# Display the image with \"salt and pepper\" noise\n",
    "cv2.imshow('Image with \"salt and pepper\" noise', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyWindow('Image with \"salt and pepper\" noise')\n",
    "\n",
    "# Saving the image with \"salt and pepper\" noise\n",
    "cv2.imwrite(os.path.join(dataDir, 'salt_and_pepper.jpg'), img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening an image\n",
    "img = cv2.imread(os.path.join(dataDir, 'ml.jpg'))\n",
    "\n",
    "b,g,r = cv2.split(img)\n",
    "\n",
    "# Display the three channels\n",
    "cv2.imshow(\"Blue channel\", b)\n",
    "cv2.imshow(\"Green channel\", g)\n",
    "cv2.imshow(\"Red channel\", r)\n",
    "\n",
    "# Close all windows after user pressed a key\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "merged_img = cv2.merge((b + 50, g, r))\n",
    "\n",
    "# Display the merged image\n",
    "cv2.imshow(\"Merged image\", merged_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyWindow('Merged image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening an image\n",
    "img = cv2.imread(os.path.join(dataDir, 'ml.jpg'))\n",
    "\n",
    "# Convert the image to HSV and split the three channels\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "h,s,v = cv2.split(img)\n",
    "\n",
    "# Display the three channels\n",
    "cv2.imshow(\"Hue channel\", h)\n",
    "cv2.imshow(\"Saturation channel\", s)\n",
    "cv2.imshow(\"Value channel\", v)\n",
    "\n",
    "# Close all windows after user pressed a key\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "merged_img = cv2.merge((h, s + 50, v))\n",
    "\n",
    "# Display the merged image\n",
    "cv2.imshow(\"Merged image\", merged_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyWindow('Merged image')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Video – acquisition and simple processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a VideoCapture Object\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"Cannot open camera\")\n",
    "    exit()\n",
    "\n",
    "frame_nr = 0\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # If frame is read correctly ret is True\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('webcam', frame)\n",
    "\n",
    "    # Wait for user to press s to save frame\n",
    "    if cv2.waitKey(1) == ord('s'):\n",
    "        frame_name = 'frame' + str(frame_nr) + '.png'\n",
    "        cv2.imwrite(os.path.join(dataDir, frame_name), frame)\n",
    "        cv2.imshow(\"Saved frame: \" + frame_name, frame)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyWindow(\"Saved frame: \" + frame_name)\n",
    "\n",
    "    # Wait for user to press q to quit\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "    frame_nr += 1\n",
    "\n",
    "# When everything is done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a VideoCapture Object\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"Cannot open camera\")\n",
    "    exit()\n",
    "\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # If frame is read correctly ret is True\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "\n",
    "    # Convert the frame to grayscale\n",
    "    grayscale = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('webcam', frame)\n",
    "    \n",
    "    # Display the grayscale frame\n",
    "    cv2.imshow('grayscale', grayscale)\n",
    "\n",
    "    # Wait for user to press q to quit\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "# When everything is done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a VideoCapture Object\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"Cannot open camera\")\n",
    "    exit()\n",
    "\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # If frame is read correctly ret is True\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "\n",
    "    # Convert the frame to grayscale\n",
    "    grayscale = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "    # Convert the grayscale frame to binary format\n",
    "    binary = cv2.threshold(grayscale, 128, 255, cv2.THRESH_BINARY)[1]\n",
    "        \n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('webcam', frame)\n",
    "    \n",
    "    # Display the grayscale frame in binary format\n",
    "    cv2.imshow('binary', binary)\n",
    "\n",
    "    # Wait for user to press q to quit\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "# When everything is done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a VideoCapture Object\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"Cannot open camera\")\n",
    "    exit()\n",
    "\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # If frame is read correctly ret is True\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "\n",
    "    # Convert the frame to HSV\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    ## Generate lower mask (0-5) and upper mask (175-180) of red\n",
    "    mask1 = cv2.inRange(hsv, (0,50,20), (5,255,255))\n",
    "    mask2 = cv2.inRange(hsv, (175,50,20), (180,255,255))\n",
    "\n",
    "    ## Merge the mask and crop the red regions\n",
    "    mask = cv2.bitwise_or(mask1, mask2)\n",
    "    tracking = cv2.bitwise_and(hsv, hsv, mask=mask)\n",
    "    tracking = cv2.cvtColor(tracking, cv2.COLOR_HSV2BGR)\n",
    "    \n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('webcam', frame)\n",
    "    \n",
    "    # Display the tracking of the color red\n",
    "    cv2.imshow('tracking red', tracking)\n",
    "\n",
    "    # Wait for user to press q to quit\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "# When everything is done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
