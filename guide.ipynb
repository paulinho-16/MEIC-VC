{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traffic Sign Detection and Classification\n",
    "This work focuses on the detection of color and shapes regarding traffic signs under many different circumstances and combinations of illumination, angle, and contrast.\n",
    "\n",
    "The first step is to import all the necessaries libraries that will be used in this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "import imutils\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Variables\n",
    "- `FILENAME`: Define the road or parse all roads inside the `data` folder. `ALL` to show all images.\n",
    "- `TYPE`: `WINDOW` to open an window with the image, `FILE` to create a file with the file.  \n",
    "- `DEBUG`: Used for debugging purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILENAME = \"ALL\"\n",
    "OUTPUT = \"WINDOW\"\n",
    "DEBUG = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Data\n",
    "\n",
    "Class used to store information about the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data:\n",
    "    def __init__(self, filename) -> None:\n",
    "        self.filename = filename\n",
    "        self.image = cv2.imread(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matching\n",
    "\n",
    "Alternative method where we try to detect traffic signs using SIFT descriptors and FLANN detector.\n",
    "\n",
    "Only applied when no traffic sign of the same type of the one used as the template for matching has been found by our main strategy (colour and shape detection)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_matches(image_data, dst, kp2, good, sign):\n",
    "    image_data.image = cv2.polylines(image_data.image, [np.int32(dst)], True, 255, 3, cv2.LINE_AA)\n",
    "    list_kp2 = [kp2[mat.trainIdx].pt for mat in good]\n",
    "    x,y = sum(i for i, _ in list_kp2), sum(j for _, j in list_kp2)\n",
    "    x_mean = int(x/len(good))\n",
    "    y_mean = int(y/len(good))\n",
    "    cv2.putText(image_data.image, sign, (x_mean - 35,y_mean - 10), cv2.FONT_HERSHEY_SIMPLEX,0.5, (255, 255, 255), 2)\n",
    "\n",
    "def matching(image1, image2, sign):\n",
    "    MIN_MATCH_COUNT = 5\n",
    "\n",
    "    img1 = cv2.imread(image1,cv2.IMREAD_GRAYSCALE) # queryImage\n",
    "    img2 = cv2.imread(image2,cv2.IMREAD_GRAYSCALE) # trainImage\n",
    "    \n",
    "    if sign == \"red triangle\":\n",
    "        scale_percent = 50 # percent of original size\n",
    "        width = int(img1.shape[1] * scale_percent / 100)\n",
    "        height = int(img1.shape[0] * scale_percent / 100)\n",
    "        dim = (width, height)\n",
    "\n",
    "        # resize image\n",
    "        img1 = cv2.resize(img1, dim, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "    img1 = cv2.GaussianBlur(img1, (5, 5), 0)\n",
    "    img2 = cv2.GaussianBlur(img2, (5, 5), 0)\n",
    "\n",
    "    # Initiate SIFT detector\n",
    "    sift = cv2.SIFT_create()\n",
    "\n",
    "    # find the keypoints and descriptors with SIFT\n",
    "    kp1, des1 = sift.detectAndCompute(img1,None)\n",
    "    kp2, des2 = sift.detectAndCompute(img2,None)\n",
    "\n",
    "    FLANN_INDEX_KDTREE = 0\n",
    "    index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "    search_params = dict(checks = 50)\n",
    "\n",
    "    flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "\n",
    "    matches = flann.knnMatch(des1,des2,k=2)\n",
    "\n",
    "    # store all the good matches as per Lowe's ratio test.\n",
    "    good = []\n",
    "    for m,n in matches:\n",
    "        if m.distance < 0.7*n.distance:\n",
    "            good.append(m)\n",
    "\n",
    "    if len(good)>MIN_MATCH_COUNT:\n",
    "        src_pts = np.float32([kp1[m.queryIdx].pt for m in good]).reshape(-1,1,2)\n",
    "        dst_pts = np.float32([kp2[m.trainIdx].pt for m in good]).reshape(-1,1,2)\n",
    "\n",
    "        M, _ = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "        \n",
    "        if M is None:\n",
    "            return (None, None, None, None)\n",
    "        \n",
    "        h,w = img1.shape\n",
    "        pts = np.float32([[0,0],[0,h-1],[w-1,h-1],[w-1,0]]).reshape(-1,1,2)\n",
    "        dst = cv2.perspectiveTransform(pts,M)\n",
    "\n",
    "    else:\n",
    "        return (None, None, None, None)\n",
    "    \n",
    "    return (dst, kp2, good, sign)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shape detection class\n",
    "\n",
    "This class is used to detect the shapes present in the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShapeDetector:\n",
    "    def __init__(self, red, blue, image) -> None:\n",
    "        self.red = red\n",
    "        self.blue = blue\n",
    "        self.image = image\n",
    "\n",
    "    def _shape_name(self, contour, colour):\n",
    "        peri = cv2.arcLength(contour, True)\n",
    "        factor = 0.02 if colour == \"blue\" else 0.01\n",
    "        approx = cv2.approxPolyDP(contour, factor * peri, True)\n",
    "\n",
    "        if len(approx) == 3:\n",
    "            return \"triangle\"\n",
    "        \n",
    "        elif len(approx) == 4:\n",
    "            (_, _, width, height) = cv2.boundingRect(approx)\n",
    "            aspect_ratio = width / float(height)\n",
    "\n",
    "            # a square will have an aspect ratio that is approximately equal to one, otherwise, the shape is a rectangle\n",
    "            return \"square\" if 0.90 <= aspect_ratio <= 1.10 else \"rectangle\"\n",
    "        \n",
    "        elif 6 <= len(approx) <= 7:\n",
    "            # if the shape is a triangle, it can have 6 or 7 vertices (due to the corner curves): verify if the sizes of its sides are on a similar ratio of those in a triangle (three of them must be way longer)\n",
    "            distances = []\n",
    "            for x,y in zip(approx, approx[1:]):\n",
    "                d = math.sqrt((x[0][1]-y[0][1])*(x[0][1]-y[0][1]) + (x[0][0]-y[0][0])*(x[0][0]-y[0][0]))\n",
    "                distances.append(d)\n",
    "\n",
    "            distances.sort()\n",
    "            if distances[len(approx) - 5] < 1/4 * distances[len(approx) - 4] or distances[len(approx) - 4] < 1/4 * distances[len(approx) - 3]:\n",
    "                return  \"triangle\"\n",
    "        \n",
    "        elif len(approx) == 8 and colour == \"red\":\n",
    "            return  \"stop\"\n",
    "\n",
    "        return \"unidentified\"\n",
    "\n",
    "    def _shape_countours(self, image, colour):\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) \n",
    "        blurred = cv2.GaussianBlur(gray, (7, 7), 0)\n",
    "        blurred = cv2.threshold(blurred, 20, 255, cv2.THRESH_BINARY)[1]\n",
    "\n",
    "        final_contours = []\n",
    "\n",
    "        # find contours in the thresholded image and initialize the shape detector\n",
    "        countours = cv2.findContours(blurred.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        countours = imutils.grab_contours(countours)\n",
    "\n",
    "        # Draw circles\n",
    "        radius = int(self.image.shape[0]*self.image.shape[1]*0.00005)\n",
    "        circles = cv2.HoughCircles(blurred, cv2.HOUGH_GRADIENT_ALT, 1.5, 30, param1=250, param2=0.75, minRadius=radius)\n",
    "\n",
    "        if circles is None: circles = [[]]\n",
    "        circles = np.uint16(np.around(circles))\n",
    "\n",
    "        processed_centers = {}\n",
    "        for i in circles[0,:]:\n",
    "            if (i[0],i[1]) in processed_centers.keys():\n",
    "                if processed_centers[(i[0],i[1])] < i[2]:\n",
    "                    processed_centers[(i[0],i[1])] = i[2]\n",
    "            else:\n",
    "                processed_centers[(i[0], i[1])] = i[2]\n",
    "\n",
    "        for c in countours:\n",
    "            # Minimum area of a valid contour\n",
    "            AREA = 1000\n",
    "            if cv2.contourArea(c) < AREA:\n",
    "                continue\n",
    "            \n",
    "            # Shape of the Image\n",
    "            shape = self._shape_name(c, colour)\n",
    "            if shape == \"unidentified\":\n",
    "                continue\n",
    "\n",
    "            # Compute the center of the contour, then detect the name of the shape using only the contour\n",
    "            M = cv2.moments(c)\n",
    "            cX = int((M[\"m10\"] / (M[\"m00\"] + 1e-7))) #* ratio)\n",
    "            cY = int((M[\"m01\"] / (M[\"m00\"] + 1e-7))) #* ratio)\n",
    "            \n",
    "            c = c.astype(\"float\")\n",
    "            c = c.astype(\"int\")\n",
    "            \n",
    "            if not (shape == \"stop\" and colour == \"blue\"): \n",
    "                final_contours.append((shape, c, colour))\n",
    "\n",
    "                # Draw and write shape name\n",
    "                cv2.drawContours(image, [c], -1, (0, 255, 0), 2)\n",
    "                classification = f\"{colour} {shape}\" if shape != \"stop\" else \"stop sign\"\n",
    "                cv2.putText(image, classification, (cX - 35, cY - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "\n",
    "        for (i[0],i[1]) in list(processed_centers.keys()):\n",
    "            circle = {'center': (i[0],i[1]), 'radius': (processed_centers[i[0],i[1]])}\n",
    "            final_contours.append((\"circle\", circle, colour))\n",
    "\n",
    "            # Draw the circle, center and write the shape name\n",
    "            cv2.circle(image,(i[0],i[1]),processed_centers[i[0],i[1]],(0,255,0),2)\n",
    "            cv2.circle(image,(i[0],i[1]),2,(0,0,255),3)\n",
    "            classification = f\"{colour} circle\"\n",
    "            cv2.putText(image, classification, (i[0] - 35, i[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "\n",
    "        return final_contours\n",
    "\n",
    "    def find_shape(self):\n",
    "        red_contours = self._shape_countours(self.red, \"red\")\n",
    "        blue_contours = self._shape_countours(self.blue, \"blue\")\n",
    "\n",
    "        return red_contours + blue_contours\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Colour Detection Class\n",
    "\n",
    "This class is used to detect the colours red and blue of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColorDetector:\n",
    "    def __init__(self, image) -> None:\n",
    "        self.image = image\n",
    "\n",
    "    def find_color(self):\n",
    "        hsv = cv2.cvtColor(self.image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "        h,s,v = cv2.split(hsv)\n",
    "        hue = hsv[:, :, 0].mean()\n",
    "        saturation = hsv[:, :, 1].mean()\n",
    "\n",
    "        # CLAHE: used to increase contrast\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "        swithCLAHE = clahe.apply(s)\n",
    "        vwithCLAHE = clahe.apply(v)\n",
    "\n",
    "        hsv = cv2.merge([h, swithCLAHE, vwithCLAHE])\n",
    "\n",
    "        # Generate lower mask and upper mask of red, depending on the average saturation and hue of the image\n",
    "        if saturation < 61:\n",
    "            if hue < 70:\n",
    "                red_mask1 = cv2.inRange(hsv, (0,90,50), (20,255,255))\n",
    "                red_mask2 = cv2.inRange(hsv, (160,90,50), (180,255,255))\n",
    "            else:\n",
    "                red_mask1 = cv2.inRange(hsv, (0,90,50), (10,255,255))\n",
    "                red_mask2 = cv2.inRange(hsv, (170,90,50), (180,255,255))\n",
    "        else:\n",
    "            if hue < 70:\n",
    "                red_mask1 = cv2.inRange(hsv, (0,30,30), (20,255,255))\n",
    "                red_mask2 = cv2.inRange(hsv, (160,30,30), (180,255,255))\n",
    "            else:\n",
    "                red_mask1 = cv2.inRange(hsv, (0,30,30), (10,255,255))\n",
    "                red_mask2 = cv2.inRange(hsv, (170,30,30), (180,255,255))\n",
    "\n",
    "        # Merge the mask and crop the red regions\n",
    "        red_mask = cv2.bitwise_or(red_mask1, red_mask2)\n",
    "\n",
    "        # Generate mask (100-140) of blue, depending on the average saturation of the image\n",
    "        if saturation < 40:\n",
    "            blue_mask = cv2.inRange(hsv, (100,130,50), (140,255,255))\n",
    "        else:\n",
    "            blue_mask = cv2.inRange(hsv, (100,220,50), (140,255,255))\n",
    "\n",
    "        red_mask = cv2.morphologyEx(red_mask, cv2.MORPH_OPEN, np.ones((3,3),np.uint8))\n",
    "\n",
    "        blue_mask = cv2.morphologyEx(blue_mask, cv2.MORPH_OPEN, np.ones((3,3),np.uint8))\n",
    "        blue_mask = cv2.morphologyEx(blue_mask, cv2.MORPH_DILATE, np.ones((3,3),np.uint8))\n",
    "\n",
    "        red = cv2.bitwise_and(self.image, self.image, mask=red_mask)\n",
    "        blue = cv2.bitwise_and(self.image, self.image, mask=blue_mask)\n",
    "\n",
    "        red_hsv = cv2.cvtColor(red, cv2.COLOR_BGR2HSV)\n",
    "        average_hsv_1 = cv2.mean(red_hsv, red_mask1)[:3]\n",
    "        average_hsv_2 = cv2.mean(red_hsv, red_mask2)[:3] \n",
    "        average_hsv_red = cv2.mean(red_hsv,  red_mask)[:3]\n",
    "\n",
    "        blue_hsv = cv2.cvtColor(blue, cv2.COLOR_BGR2HSV)\n",
    "        average_hsv_blue = cv2.mean(blue_hsv,  blue_mask)[:3]\n",
    "\n",
    "        min_value_saturation_red = red_hsv[np.where(red_hsv[:,:,1]>0)][:,1].min() if red_hsv.any() else 100\n",
    "        min_value_saturation_blue = blue_hsv[np.where(blue_hsv[:,:,1]>0)][:,1].min() if blue_hsv.any() else 100\n",
    "\n",
    "        red_threshold = (average_hsv_red[1] + min_value_saturation_red) / 2\n",
    "        blue_threshold = (average_hsv_blue[1] + min_value_saturation_blue) / 2\n",
    "\n",
    "        max_red1 = 10 if average_hsv_1[0] <= 15 else 20\n",
    "        min_red2 = 170 if average_hsv_2[0] > 175 else 160\n",
    "\n",
    "        red_mask1 = cv2.inRange(hsv, (0, red_threshold, 50), (max_red1, 255, 255))\n",
    "        red_mask2 = cv2.inRange(hsv, (min_red2, red_threshold, 50), (180, 255, 255))\n",
    "        \n",
    "        blue_mask = cv2.inRange(hsv, (90, blue_threshold, 50), (130, 255, 255))\n",
    "\n",
    "        # Merge the mask and crop the red regions\n",
    "        red_mask = cv2.bitwise_or(red_mask1, red_mask2)\n",
    "        red_mask = cv2.morphologyEx(red_mask, cv2.MORPH_OPEN, np.ones((3,3),np.uint8))\n",
    "\n",
    "        blue_mask = cv2.morphologyEx(blue_mask, cv2.MORPH_OPEN, np.ones((3,3),np.uint8))\n",
    "        blue_mask = cv2.morphologyEx(blue_mask, cv2.MORPH_DILATE, np.ones((3,3),np.uint8))\n",
    "\n",
    "        red = cv2.bitwise_and(self.image, self.image, mask=red_mask)\n",
    "        blue = cv2.bitwise_and(self.image, self.image, mask=blue_mask)\n",
    "\n",
    "        # Show red tracing\n",
    "        if DEBUG:\n",
    "            cv2.imshow('Red Color', red)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "        # Show blue tracing\n",
    "        if DEBUG:\n",
    "            cv2.imshow('Blue Color', blue)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "        mask = cv2.bitwise_or(red, blue)\n",
    "        result = cv2.bitwise_and(self.image, mask)\n",
    "\n",
    "        # Show blue and red colour tracing\n",
    "        if DEBUG:\n",
    "            cv2.imshow('Red and Blue Color Detection', result)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "        \n",
    "        return (red, blue, result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traffic Sign Detection\n",
    "\n",
    "Function that detects the traffic signs in a given image, drawing their contours and writing their names in that image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_image(image_data):\n",
    "    color_detector = ColorDetector(image_data.image)\n",
    "    red_result, blue_result, color_result = color_detector.find_color()\n",
    "\n",
    "    shape_detector = ShapeDetector(red_result, blue_result, color_result)\n",
    "    contours = shape_detector.find_shape()\n",
    "\n",
    "    processed_contours = []\n",
    "    for t, c, colour in contours:\n",
    "        if t == \"circle\":\n",
    "            center = (c['center'][0], c['center'][1])\n",
    "        else:\n",
    "            M = cv2.moments(c)\n",
    "            cX = int((M[\"m10\"] / (M[\"m00\"] + 1e-7)))\n",
    "            cY = int((M[\"m01\"] / (M[\"m00\"] + 1e-7)))\n",
    "            center = (cX, cY)\n",
    "\n",
    "        contour_radius = c['radius'] if t == \"circle\" else cv2.minEnclosingCircle(c)[1]\n",
    "        if not processed_contours:\n",
    "            processed_contours.append((t, c, colour))\n",
    "            continue\n",
    "\n",
    "        invalid_contours = []\n",
    "        append_contour = False\n",
    "        processed_verified = 0\n",
    "\n",
    "        for (tp, cp, colourp) in processed_contours:\n",
    "            circle_inside = False\n",
    "            dist = 0\n",
    "            processed_contour_radius = cp['radius'] if tp == \"circle\" else cv2.minEnclosingCircle(cp)[1]\n",
    "\n",
    "            if tp == \"circle\":\n",
    "                if (int(cp['center'][0]) - int(center[0]))**2 + (int(cp['center'][1]) - int(center[1]))**2 < processed_contour_radius**2: # Check if center of circle is inside the contour\n",
    "                    circle_inside = True\n",
    "            else:\n",
    "                dist = cv2.pointPolygonTest(cp, center, True)\n",
    "            if dist > 0 or circle_inside: # Center of the contour is inside a processed contour\n",
    "                if (contour_radius >= 2/3 * processed_contour_radius and colour == \"red\" and not (t == \"stop\" or tp == \"stop\")) or (contour_radius >= processed_contour_radius and colour != \"blue\"): # The radius of the contour is bigger than the radius of the processed contour\n",
    "                    invalid_contours.append((tp, cp, colourp))\n",
    "                    append_contour = True\n",
    "            else:\n",
    "                processed_verified += 1\n",
    "\n",
    "        for i in invalid_contours:\n",
    "            processed_contours.remove(i)\n",
    "        if append_contour or (processed_verified == len(processed_contours)):\n",
    "            processed_contours.append((t, c, colour))\n",
    "\n",
    "    signs = []\n",
    "    stop_count = 0\n",
    "    rectangle_square = 0\n",
    "    triangle_count = 0\n",
    "    \n",
    "    for t, c, colour in processed_contours:\n",
    "        signs.append(t)\n",
    "        if t == \"stop\": \n",
    "            stop_count += 1\n",
    "        elif t == \"square\" or t == \"rectangle\":\n",
    "            rectangle_square += 1\n",
    "        elif t == \"triangle\":\n",
    "            triangle_count += 1\n",
    "\n",
    "    dst_found = []\n",
    "\n",
    "    if stop_count == 0:\n",
    "        stop_sign = os.path.join(\"./data/matching\", \"stop.png\")\n",
    "        dst, kp2, good, sign = matching(stop_sign, image_data.filename, \"STOP sign\")\n",
    "        if dst is not None:\n",
    "            draw_matches(image_data, dst, kp2, good, sign)\n",
    "            dst_found.append(dst)\n",
    "    \n",
    "    if rectangle_square == 0:\n",
    "        pedestrian1 = os.path.join(\"./data/matching\", \"pedestrian_left.png\")\n",
    "        dst_left, kp2_left, good_left, sign_left = matching(pedestrian1, image_data.filename, \"blue square\")\n",
    "        pedestrian2 = os.path.join(\"./data/matching\", \"pedestrian_right.png\")\n",
    "        dst_right, kp2_right, good_right, sign_right = matching(pedestrian2, image_data.filename, \"blue square\")\n",
    "\n",
    "        if dst_left is not None and dst_right is not None:\n",
    "            if len(good_left) > len(good_right):\n",
    "                draw_matches(image_data, dst_left, kp2_left, good_left, sign_left)\n",
    "                dst_found.append(dst_left)\n",
    "            else:\n",
    "                draw_matches(image_data, dst_right, kp2_right, good_right, sign_right)\n",
    "                dst_found.append(dst_right)\n",
    "        elif dst_left is not None:\n",
    "            draw_matches(image_data, dst_left, kp2_left, good_left, sign_left)\n",
    "            dst_found.append(dst_left)\n",
    "        elif dst_right is not None:\n",
    "            draw_matches(image_data, dst_right, kp2_right, good_right, sign_right)\n",
    "            dst_found.append(dst_right)\n",
    "\n",
    "    if triangle_count == 0:        \n",
    "        triangle_sign = os.path.join(\"./data/matching\", \"bump.png\")\n",
    "        \n",
    "        dst, kp2, good, sign = matching(triangle_sign, image_data.filename, \"red triangle\")\n",
    "        if dst is not None:\n",
    "            draw_matches(image_data, dst, kp2, good, sign)\n",
    "            dst_found.append(dst)\n",
    "\n",
    "    for t, c, colour in processed_contours:\n",
    "        signs.append(t)\n",
    "        if t == \"circle\":\n",
    "            inside_matching = False\n",
    "            for dst in dst_found:\n",
    "                dist = cv2.pointPolygonTest(dst, c['center'], True)\n",
    "                if dist > 0:\n",
    "                    inside_matching = True\n",
    "\n",
    "            if not inside_matching:\n",
    "                cv2.circle(image_data.image,(c['center']),c['radius'],(0,255,0),2) # Draw the outer circle\n",
    "                cv2.circle(image_data.image,(c['center']),2,(0,0,255),3) # Draw the center of the circle\n",
    "                cv2.putText(image_data.image, f\"{colour} circle\", (c['center'][0] - 35, c['center'][1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2) # Write the name of the sign\n",
    "        else:\n",
    "            if t == \"stop\": stop_count += 1\n",
    "            M = cv2.moments(c)\n",
    "            cX = int((M[\"m10\"] / (M[\"m00\"] + 1e-7)))\n",
    "            cY = int((M[\"m01\"] / (M[\"m00\"] + 1e-7)))\n",
    "            cv2.drawContours(image_data.image, [c], -1, (0, 255, 0), 2)\n",
    "            classification = f\"{colour} {t}\" if t != \"stop\" else \"stop sign\"\n",
    "            cv2.putText(image_data.image, classification, (cX - 35, cY - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "        \n",
    "    return signs, image_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will run the main code, which processes the requested images.\n",
    "\n",
    "- Press any key to see the next image, if any\n",
    "- Press the `Esc` key to exit the application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected signs: ['stop', 'stop']\n",
      "Real signs: ['stop']\n",
      "Detected signs: ['stop', 'circle', 'circle', 'stop', 'circle', 'circle']\n",
      "Real signs: ['stop']\n",
      "Detected signs: ['stop', 'circle', 'stop', 'circle']\n",
      "Real signs: ['stop']\n",
      "Detected signs: ['circle', 'circle']\n",
      "Real signs: ['stop']\n",
      "Detected signs: ['stop', 'circle', 'circle', 'stop', 'circle', 'circle']\n",
      "Real signs: ['stop']\n",
      "Detected signs: ['stop', 'stop']\n",
      "Real signs: ['stop']\n",
      "Detected signs: ['stop', 'stop']\n",
      "Real signs: ['stop']\n",
      "Detected signs: ['stop', 'stop']\n",
      "Real signs: ['stop']\n",
      "Detected signs: ['stop', 'stop']\n",
      "Real signs: ['stop']\n",
      "Detected signs: ['stop', 'circle', 'stop', 'circle']\n",
      "Real signs: ['stop']\n",
      "Detected signs: ['stop', 'stop']\n",
      "Real signs: ['stop']\n",
      "Detected signs: []\n",
      "Real signs: ['stop']\n",
      "Detected signs: ['stop', 'stop']\n",
      "Real signs: ['stop']\n",
      "Detected signs: ['stop', 'circle', 'circle', 'stop', 'circle', 'circle']\n",
      "Real signs: ['stop']\n",
      "Detected signs: ['circle', 'circle', 'circle', 'circle', 'circle', 'circle', 'circle', 'circle', 'circle', 'circle']\n",
      "Real signs: ['stop']\n",
      "Detected signs: ['stop', 'stop']\n",
      "Real signs: ['stop']\n",
      "Detected signs: ['stop', 'stop']\n",
      "Real signs: ['stop']\n",
      "Detected signs: ['stop', 'stop']\n",
      "Real signs: ['stop']\n",
      "Detected signs: ['circle', 'circle']\n",
      "Real signs: ['stop']\n",
      "Detected signs: ['stop', 'stop']\n",
      "Real signs: ['stop']\n",
      "Detected signs: ['stop', 'stop']\n",
      "Real signs: ['stop']\n",
      "Detected signs: ['circle', 'circle', 'circle', 'circle']\n",
      "Real signs: ['stop', 'trafficlight']\n",
      "Detected signs: []\n",
      "Real signs: ['stop']\n",
      "Detected signs: ['stop', 'stop']\n",
      "Real signs: ['stop']\n",
      "Detected signs: ['stop', 'stop']\n",
      "Real signs: ['stop']\n",
      "Detected signs: ['stop', 'stop']\n",
      "Real signs: ['stop']\n",
      "Detected signs: ['stop', 'circle', 'stop', 'circle']\n",
      "Real signs: ['stop']\n",
      "Detected signs: ['stop', 'circle', 'circle', 'stop', 'circle', 'circle']\n",
      "Real signs: ['stop']\n",
      "Detected signs: ['stop', 'stop']\n",
      "Real signs: ['stop']\n",
      "Detected signs: ['stop', 'stop']\n",
      "Real signs: ['stop']\n",
      "Detected signs: []\n",
      "Real signs: ['stop']\n",
      "Detected signs: ['stop', 'stop']\n",
      "Real signs: ['stop']\n",
      "Detected signs: []\n",
      "Real signs: ['stop']\n",
      "Detected signs: ['stop', 'stop']\n",
      "Real signs: ['stop']\n",
      "Detected signs: ['circle', 'circle']\n",
      "Real signs: ['stop']\n",
      "Detected signs: ['stop', 'stop']\n",
      "Real signs: ['stop']\n",
      "Detected signs: []\n",
      "Real signs: ['stop']\n",
      "Detected signs: ['circle', 'circle']\n",
      "Real signs: ['stop']\n",
      "Detected signs: []\n",
      "Real signs: ['stop']\n",
      "Detected signs: ['stop', 'stop']\n",
      "Real signs: ['stop']\n",
      "Detected signs: ['stop', 'stop']\n",
      "Real signs: ['stop']\n",
      "Detected signs: ['stop', 'stop']\n",
      "Real signs: ['stop']\n",
      "Detected signs: ['stop', 'stop']\n",
      "Real signs: ['stop']\n",
      "Detected signs: []\n",
      "Real signs: ['stop']\n",
      "Detected signs: []\n",
      "Real signs: ['stop']\n",
      "Detected signs: ['circle', 'circle']\n",
      "Real signs: ['stop']\n",
      "Detected signs: ['stop', 'circle', 'stop', 'circle']\n",
      "Real signs: ['stop']\n",
      "Detected signs: ['circle', 'circle', 'circle', 'circle']\n",
      "Real signs: ['stop']\n",
      "Detected signs: ['circle', 'circle']\n",
      "Real signs: ['speedlimit']\n",
      "Detected signs: ['circle', 'circle']\n",
      "Real signs: ['speedlimit']\n",
      "Detected signs: ['circle', 'circle']\n",
      "Real signs: ['speedlimit']\n",
      "Detected signs: ['circle', 'circle']\n",
      "Real signs: ['speedlimit']\n",
      "Detected signs: ['circle', 'circle']\n",
      "Real signs: ['speedlimit']\n",
      "Detected signs: []\n",
      "Real signs: ['speedlimit']\n",
      "Detected signs: ['circle', 'circle', 'circle', 'circle']\n",
      "Real signs: ['speedlimit']\n",
      "Detected signs: []\n",
      "Real signs: ['speedlimit']\n",
      "Detected signs: []\n",
      "Real signs: ['speedlimit']\n",
      "Detected signs: ['circle', 'circle', 'circle', 'circle']\n",
      "Real signs: ['speedlimit']\n",
      "Detected signs: ['circle', 'circle']\n",
      "Real signs: ['speedlimit']\n",
      "Detected signs: ['circle', 'circle']\n",
      "Real signs: ['speedlimit']\n",
      "Detected signs: []\n",
      "Real signs: ['speedlimit']\n",
      "Detected signs: ['circle', 'circle']\n",
      "Real signs: ['speedlimit']\n"
     ]
    }
   ],
   "source": [
    "def process_image(road_number):\n",
    "    filename = 'road' + str(road_number) + '.png'\n",
    "    image_data = Data(os.path.join(\"./data\", filename))\n",
    "    detected_signs, output_image = evaluate_image(image_data)\n",
    "        \n",
    "    with open('./data/annotations/road' + str(road_number) + '.xml', 'r') as f: data = f.read()\n",
    "    root = ET.fromstring(data)\n",
    "\n",
    "    real_signs = []\n",
    "    for content in root.findall('.//object/name'):\n",
    "        real_signs.append(content.text)\n",
    "\n",
    "    print(f'Detected signs: {detected_signs}')\n",
    "    print(f'Real signs: {real_signs}')\n",
    "\n",
    "    # Show the output image\n",
    "    if OUTPUT == \"WINDOW\":\n",
    "        cv2.imshow('Final Result', output_image.image)\n",
    "    else:\n",
    "        cv2.imwrite(f'output/{filename}', image_data.image)\n",
    "\n",
    "if not os.path.exists('./output'):\n",
    "    os.makedirs('./output')\n",
    "\n",
    "if FILENAME == \"ALL\":\n",
    "    for i in range(52, 877):\n",
    "        process_image(i)\n",
    "        k = cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "        if k == 27:\n",
    "            break\n",
    "else:\n",
    "    process_image(FILENAME)\n",
    "\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ce41d2c9079f2c783da2c5a9243470309928341d0f7f9360b413f846a0d7760d"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
