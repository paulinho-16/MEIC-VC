{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traffic Sign Detection and Classification\n",
    "This work focuses on the detection of color and shapes regarding traffic signs under many different circumstances and combinations of illumination, angle, and contrast.\n",
    "\n",
    "The first step is to import all the necessaries libraries that will be used in this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "import imutils\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Variables\n",
    "- `FILENAME`: Define the road or parse all roads inside the `data` folder. `ALL` to show all images.\n",
    "- `TYPE`: `WINDOW` to open an window with the image, `FILE` to create a file with the file.  \n",
    "- `Debug`: Used for testing purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILENAME = \"ALL\"\n",
    "OUTPUT = \"WINDOW\"\n",
    "DEBUG = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Data\n",
    "\n",
    "Class used to store information about the image.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data:\n",
    "    def __init__(self, filename) -> None:\n",
    "        self.filename = filename\n",
    "        self.image = cv2.imread(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matching(image1, image2, image_data2, sign):\n",
    "\n",
    "    MIN_MATCH_COUNT = 5\n",
    "\n",
    "    img1 = cv2.imread(image1,cv2.IMREAD_GRAYSCALE)          # queryImage\n",
    "    img2 = cv2.imread(image2,cv2.IMREAD_GRAYSCALE) # trainImage\n",
    "    \n",
    "    if sign == \"red triangle\":\n",
    "        scale_percent = 50 # percent of original size\n",
    "        width = int(img1.shape[1] * scale_percent / 100)\n",
    "        height = int(img1.shape[0] * scale_percent / 100)\n",
    "        dim = (width, height)\n",
    "\n",
    "        # resize image\n",
    "        img1 = cv2.resize(img1, dim, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "    img1 = cv2.GaussianBlur(img1, (5, 5), 0)\n",
    "    img2 = cv2.GaussianBlur(img2, (5, 5), 0)\n",
    "\n",
    "    # Initiate SIFT detector\n",
    "    sift = cv2.SIFT_create()\n",
    "\n",
    "    # find the keypoints and descriptors with SIFT\n",
    "    kp1, des1 = sift.detectAndCompute(img1,None)\n",
    "    kp2, des2 = sift.detectAndCompute(img2,None)\n",
    "\n",
    "    FLANN_INDEX_KDTREE = 0\n",
    "    index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "    search_params = dict(checks = 50)\n",
    "\n",
    "    flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "\n",
    "    matches = flann.knnMatch(des1,des2,k=2)\n",
    "\n",
    "    # store all the good matches as per Lowe's ratio test.\n",
    "    good = []\n",
    "    for m,n in matches:\n",
    "        if m.distance < 0.7*n.distance:\n",
    "            good.append(m)\n",
    "\n",
    "    if len(good)>MIN_MATCH_COUNT:\n",
    "        src_pts = np.float32([ kp1[m.queryIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "        dst_pts = np.float32([ kp2[m.trainIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "\n",
    "        M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC,5.0)\n",
    "        matchesMask = mask.ravel().tolist()\n",
    "        \n",
    "        if M is None:\n",
    "            return\n",
    "        \n",
    "        h,w = img1.shape\n",
    "        pts = np.float32([ [0,0],[0,h-1],[w-1,h-1],[w-1,0] ]).reshape(-1,1,2)\n",
    "        dst = cv2.perspectiveTransform(pts,M)\n",
    "\n",
    "        image_data2.image = cv2.polylines(image_data2.image,[np.int32(dst)],True,255,3, cv2.LINE_AA)\n",
    "\n",
    "    else:\n",
    "        #print(\"Not enough matches are found - \" + str(len(good)) + \"/\" + str(MIN_MATCH_COUNT))\n",
    "        matchesMask = None\n",
    "        return\n",
    "    \n",
    "    print(\"Number \" + image1)\n",
    "    print(len(good))\n",
    "    draw_params = dict(matchColor = (0,255,0), # draw matches in green color\n",
    "                       singlePointColor = None,\n",
    "                       matchesMask = matchesMask, # draw only inliers\n",
    "                       flags = 2)\n",
    "    \n",
    "    list_kp2 = [kp2[mat.trainIdx].pt for mat in good]\n",
    "    x,y = sum(i for i, j in list_kp2), sum(j for i, j in list_kp2)\n",
    "    x_mean = int(x/len(good))\n",
    "    y_mean = int(y/len(good))\n",
    "    \n",
    "    cv2.putText(image_data2.image, sign, (x_mean - 35,y_mean - 10), cv2.FONT_HERSHEY_SIMPLEX,0.5, (255, 255, 255), 2)\n",
    "    \n",
    "    # img3 = cv2.drawMatches(img1,kp1,img2,kp2,good,None,**draw_params)\n",
    "    \n",
    "    # plt.imshow(img3, 'gray'),plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shape detection class\n",
    "\n",
    "This class is used to detect the Shape present in the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShapeDetector:\n",
    "    def __init__(self, red, blue, image) -> None:\n",
    "        self.red = red\n",
    "        self.blue = blue\n",
    "        self.image = image\n",
    "\n",
    "    def _shape_name(self, contour, colour):\n",
    "        peri = cv2.arcLength(contour, True)\n",
    "        factor = 0.02 if colour == \"blue\" else 0.01\n",
    "        approx = cv2.approxPolyDP(contour, factor * peri, True) # Estava 0.01, verificar tudo de novo a ver se não estraga...            \n",
    "\n",
    "        if len(approx) == 3:\n",
    "            return \"triangle\"\n",
    "        elif len(approx) == 4:\n",
    "            (_, _, width, height) = cv2.boundingRect(approx)\n",
    "            aspect_ratio = width / float(height)\n",
    "\n",
    "            # a square will have an aspect ratio that is approximately equal to one, otherwise, the shape is a rectangle\n",
    "            return \"square\" if 0.90 <= aspect_ratio <= 1.10 else \"rectangle\"\n",
    "        elif 6 <= len(approx) <= 7:\n",
    "            # if the shape is a triangle, it will have can have 6 or 7 vertices (due to the corner curves)\n",
    "            distances = []\n",
    "            for x,y in zip(approx, approx[1:]):\n",
    "                d = math.sqrt((x[0][1]-y[0][1])*(x[0][1]-y[0][1]) + (x[0][0]-y[0][0])*(x[0][0]-y[0][0]))\n",
    "                distances.append(d)\n",
    "\n",
    "            distances.sort()\n",
    "            if distances[len(approx) - 5] < 1/4 * distances[len(approx) - 4] or distances[len(approx) - 4] < 1/4 * distances[len(approx) - 3]:\n",
    "                return  \"triangle\"\n",
    "        elif len(approx) == 8 and colour == \"red\":\n",
    "            return  \"stop\"\n",
    "\n",
    "        print(len(approx))\n",
    "        return \"unidentified\"\n",
    "\n",
    "    def _shape_countours(self, image, colour):\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) \n",
    "        blurred = cv2.GaussianBlur(gray, (7, 7), 0)\n",
    "        blurred = cv2.threshold(blurred, 20, 255, cv2.THRESH_BINARY)[1]\n",
    "\n",
    "        # cv2.imshow('THRESGOL', blurred)\n",
    "        # cv2.waitKey(0)\n",
    "        # cv2.destroyAllWindows()\n",
    "\n",
    "        final_contours = []\n",
    "\n",
    "        # find contours in the thresholded image and initialize the shape detector\n",
    "        countours = cv2.findContours(blurred.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        countours = imutils.grab_contours(countours)\n",
    "\n",
    "        # Draw circles\n",
    "        # TODO: Verify better values\n",
    "         # param1 estava a 100, mudamos por causa do road53.png, mudamos param2 de 0.8 para 0.5\n",
    "        radius = int(self.image.shape[0]*self.image.shape[1]*0.00005)\n",
    "        print(\"Radius \"+str(radius))\n",
    "        circles = cv2.HoughCircles(blurred, cv2.HOUGH_GRADIENT_ALT, 1.5, 30, param1=250, param2=0.75, minRadius=radius)\n",
    "\n",
    "        if circles is None: circles = [[]]\n",
    "        circles = np.uint16(np.around(circles))\n",
    "\n",
    "        processed_centers = {}\n",
    "        for i in circles[0,:]:\n",
    "            if (i[0],i[1]) in processed_centers.keys():\n",
    "                if processed_centers[(i[0],i[1])] < i[2]:\n",
    "                    processed_centers[(i[0],i[1])] = i[2]\n",
    "            else:\n",
    "                processed_centers[(i[0], i[1])] = i[2]\n",
    "\n",
    "        for c in countours:\n",
    "            # TODO: Area?\n",
    "            # Area of the Image\n",
    "            # AREA = img.shape[0]*img.shape[1]/20\n",
    "            AREA = 1000\n",
    "            if cv2.contourArea(c) < AREA:\n",
    "                continue\n",
    "            \n",
    "            # Shape of the Image\n",
    "            shape = self._shape_name(c, colour)\n",
    "            if shape == \"unidentified\":\n",
    "                continue\n",
    "\n",
    "            # Compute the center of the contour, then detect the name of the shape using only the contour\n",
    "            M = cv2.moments(c)\n",
    "            cX = int((M[\"m10\"] / (M[\"m00\"] + 1e-7))) #* ratio)\n",
    "            cY = int((M[\"m01\"] / (M[\"m00\"] + 1e-7))) #* ratio)\n",
    "            \n",
    "            # TODO: Ratio?\n",
    "            # multiply the contour (x, y)-coordinates by the resize ratio, then draw the contours and the name of the shape on the image\n",
    "            c = c.astype(\"float\")\n",
    "            # c *= ratio\n",
    "            c = c.astype(\"int\")\n",
    "            \n",
    "            # TODO: If the building is red still detects a stop sign - road78.png\n",
    "            # if not contains_circle:\n",
    "            if not (shape == \"stop\" and colour == \"blue\"): \n",
    "                final_contours.append((shape, c, colour))\n",
    "\n",
    "                # Draw and write shape name\n",
    "                cv2.drawContours(image, [c], -1, (0, 255, 0), 2)\n",
    "                classification = f\"{colour} {shape}\" if shape != \"stop\" else \"stop sign\"\n",
    "                cv2.putText(image, classification, (cX - 35, cY - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "\n",
    "\n",
    "        for (i[0],i[1]) in list(processed_centers.keys()):\n",
    "            circle = {'center': (i[0],i[1]), 'radius': (processed_centers[i[0],i[1]])}\n",
    "            final_contours.append((\"circle\", circle, colour))\n",
    "\n",
    "            # Draw the circle, center and write the shape name\n",
    "            cv2.circle(image,(i[0],i[1]),processed_centers[i[0],i[1]],(0,255,0),2)\n",
    "            cv2.circle(image,(i[0],i[1]),2,(0,0,255),3)\n",
    "            classification = f\"{colour} circle\"\n",
    "            cv2.putText(image, classification, (i[0] - 35, i[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "\n",
    "        return final_contours\n",
    "\n",
    "    def find_shape(self):\n",
    "        red_contours = self._shape_countours(self.red, \"red\")\n",
    "        blue_contours = self._shape_countours(self.blue, \"blue\")\n",
    "\n",
    "        return red_contours + blue_contours\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Color Detection Class\n",
    "\n",
    "Used to detect the color of the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColorDetector:\n",
    "    def __init__(self, image) -> None:\n",
    "        self.image = image\n",
    "\n",
    "    def find_color(self):\n",
    "        hsv = cv2.cvtColor(self.image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "        h,s,v = cv2.split(hsv)\n",
    "        hue = hsv[:, :, 0].mean()\n",
    "        saturation = hsv[:, :, 1].mean()\n",
    "\n",
    "        # CLAHE: used to increase contrast\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "        swithCLAHE = clahe.apply(s)\n",
    "        vwithCLAHE = clahe.apply(v)\n",
    "\n",
    "        hsv = cv2.merge([h, swithCLAHE, vwithCLAHE])\n",
    "\n",
    "        # Generate lower mask (0-10) and upper mask (170-180) of red\n",
    "        if saturation < 61:\n",
    "            if hue < 70:\n",
    "                red_mask1 = cv2.inRange(hsv, (0,90,50), (20,255,255)) # deteta tudo no road56.png\n",
    "                red_mask2 = cv2.inRange(hsv, (160,90,50), (180,255,255)) # deteta tudo no road56.png\n",
    "            else:\n",
    "                red_mask1 = cv2.inRange(hsv, (0,90,50), (10,255,255)) # deteta tudo no road56.png\n",
    "                red_mask2 = cv2.inRange(hsv, (170,90,50), (180,255,255)) # deteta tudo no road56.png\n",
    "        else:\n",
    "            if hue < 70:\n",
    "                red_mask1 = cv2.inRange(hsv, (0,30,30), (20,255,255)) # deteta tudo no road66.png\n",
    "                red_mask2 = cv2.inRange(hsv, (160,30,30), (180,255,255)) # deteta tudo no road66.png\n",
    "            else:\n",
    "                red_mask1 = cv2.inRange(hsv, (0,30,30), (10,255,255)) # deteta tudo no road66.png\n",
    "                red_mask2 = cv2.inRange(hsv, (170,30,30), (180,255,255)) # deteta tudo no road66.png\n",
    "\n",
    "            # red_mask1 = cv2.inRange(hsv, (0,65,30), (20,255,255)) # deteta tudo no road57.png\n",
    "            # red_mask2 = cv2.inRange(hsv, (160,65,30), (180,255,255)) # deteta tudo no road57.png\n",
    "            # red_mask1 = cv2.inRange(hsv, (0,30,30), (20,255,255)) # deteta tudo no road66.png\n",
    "            # red_mask2 = cv2.inRange(hsv, (160,30,30), (180,255,255)) # deteta tudo no road66.png\n",
    "\n",
    "        # Merge the mask and crop the red regions\n",
    "        red_mask = cv2.bitwise_or(red_mask1, red_mask2)\n",
    "\n",
    "        # Generate mask (100-140) of blue\n",
    "        if saturation < 40:\n",
    "            blue_mask = cv2.inRange(hsv, (100,130,50), (140,255,255))\n",
    "        else:\n",
    "            blue_mask = cv2.inRange(hsv, (100,220,50), (140,255,255))\n",
    "\n",
    "        print(\"saturacao\" + str(saturation))\n",
    "        print(\"hue\" + str(hue))\n",
    "        red_mask = cv2.morphologyEx(red_mask, cv2.MORPH_OPEN, np.ones((3,3),np.uint8))\n",
    "        # red_mask = cv2.morphologyEx(red_mask, cv2.MORPH_DILATE, np.ones((3,3),np.uint8))\n",
    "\n",
    "        blue_mask = cv2.morphologyEx(blue_mask, cv2.MORPH_OPEN, np.ones((3,3),np.uint8))\n",
    "        blue_mask = cv2.morphologyEx(blue_mask, cv2.MORPH_DILATE, np.ones((3,3),np.uint8))\n",
    "\n",
    "        red = cv2.bitwise_and(self.image, self.image, mask=red_mask)\n",
    "        blue = cv2.bitwise_and(self.image, self.image, mask=blue_mask)\n",
    "\n",
    "        red_hsv = cv2.cvtColor(red, cv2.COLOR_BGR2HSV)\n",
    "        average_hsv_1 = cv2.mean(red_hsv, red_mask1)[:3]\n",
    "        average_hsv_2 = cv2.mean(red_hsv, red_mask2)[:3] \n",
    "        average_hsv_red = cv2.mean(red_hsv,  red_mask)[:3]\n",
    "\n",
    "        blue_hsv = cv2.cvtColor(blue, cv2.COLOR_BGR2HSV)\n",
    "        average_hsv_blue = cv2.mean(blue_hsv,  blue_mask)[:3]\n",
    "\n",
    "        min_value_saturation_red = red_hsv[np.where(red_hsv[:,:,1]>0)][:,1].min() if red_hsv.any() else 100\n",
    "        min_value_saturation_blue = blue_hsv[np.where(blue_hsv[:,:,1]>0)][:,1].min() if blue_hsv.any() else 100\n",
    "\n",
    "        red_threshold = (average_hsv_red[1] + min_value_saturation_red) / 2\n",
    "        blue_threshold = (average_hsv_blue[1] + min_value_saturation_blue) / 2\n",
    "\n",
    "        print(\"thresohold azul\" + str(blue_threshold))\n",
    "        # blue_threshold = 200\n",
    "\n",
    "        max_red1 = 10 if average_hsv_1[0] <= 15 else 20\n",
    "        min_red2 = 170 if average_hsv_2[0] > 175 else 160 # TODO: devia ser average_hsv_2, mudar para verificar se não estraga\n",
    "\n",
    "        red_mask1 = cv2.inRange(hsv, (0, red_threshold, 50), (max_red1, 255, 255))\n",
    "        red_mask2 = cv2.inRange(hsv, (min_red2, red_threshold, 50), (180, 255, 255))\n",
    "        \n",
    "        blue_mask = cv2.inRange(hsv, (90, blue_threshold, 50), (130, 255, 255))\n",
    "\n",
    "        # Merge the mask and crop the red regions\n",
    "        red_mask = cv2.bitwise_or(red_mask1, red_mask2)\n",
    "        red_mask = cv2.morphologyEx(red_mask, cv2.MORPH_OPEN, np.ones((3,3),np.uint8))\n",
    "\n",
    "        blue_mask = cv2.morphologyEx(blue_mask, cv2.MORPH_OPEN, np.ones((3,3),np.uint8))\n",
    "        blue_mask = cv2.morphologyEx(blue_mask, cv2.MORPH_DILATE, np.ones((3,3),np.uint8))\n",
    "\n",
    "        red = cv2.bitwise_and(self.image, self.image, mask=red_mask)\n",
    "        blue = cv2.bitwise_and(self.image, self.image, mask=blue_mask)\n",
    "\n",
    "        # Show red tracing\n",
    "        if DEBUG:\n",
    "            cv2.imshow('Red Color', red)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "        # Show blue tracing\n",
    "        if DEBUG:\n",
    "            cv2.imshow('Blue Color', blue)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "        mask = cv2.bitwise_or(red, blue)\n",
    "        result = cv2.bitwise_and(self.image, mask)\n",
    "\n",
    "        # Show blue and red tracing\n",
    "        if DEBUG:\n",
    "            cv2.imshow('Red Color Detection', red)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "        return (\"gray\", red, blue, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for i in range(52,100):\n",
    "    matching_stop(\"stop.png\",\"road\"+str(i)+\".png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Evaluation\n",
    "\n",
    "Function to evaluate the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_image(image_data):\n",
    "    color_detector = ColorDetector(image_data.image)\n",
    "    image_color, red_result, blue_result, color_result = color_detector.find_color()\n",
    "\n",
    "    shape_detector = ShapeDetector(red_result, blue_result, color_result)\n",
    "    contours = shape_detector.find_shape()\n",
    "\n",
    "    processed_contours = []\n",
    "    for t, c, colour in contours:\n",
    "        if t == \"circle\":\n",
    "            center = (c['center'][0], c['center'][1])\n",
    "        else:\n",
    "            M = cv2.moments(c)\n",
    "            cX = int((M[\"m10\"] / (M[\"m00\"] + 1e-7))) #* ratio)\n",
    "            cY = int((M[\"m01\"] / (M[\"m00\"] + 1e-7))) #* ratio)\n",
    "            center = (cX, cY)\n",
    "\n",
    "        contour_radius = c['radius'] if t == \"circle\" else cv2.minEnclosingCircle(c)[1]\n",
    "        if not processed_contours:\n",
    "            processed_contours.append((t, c, colour))\n",
    "            continue\n",
    "\n",
    "        invalid_contours = []\n",
    "        append_contour = False\n",
    "        processed_verified = 0\n",
    "        \n",
    "        #print(f'LEN PROCESSED:::: {len(processed_contours)}')\n",
    "\n",
    "        for (tp, cp, colourp) in processed_contours:\n",
    "            #print('PROCESSED')\n",
    "            #print(f'TYPE {tp}, colour {colourp}')\n",
    "\n",
    "            circle_inside = False\n",
    "            dist = 0\n",
    "            processed_contour_radius = cp['radius'] if tp == \"circle\" else cv2.minEnclosingCircle(cp)[1]\n",
    "\n",
    "            if tp == \"circle\":\n",
    "                #print(f'processed_contour_radius: {processed_contour_radius}')\n",
    "                #print(f'center do processed: {int(cp[\"center\"][0]), int(cp[\"center\"][1])}')\n",
    "                #print(f'center do contorno: {int(center[0]), int(center[1])}')\n",
    "                #print(f'quadrado 1: {(int(cp[\"center\"][0]) - int(center[0]))**2}')\n",
    "                #print(f'quadrado 2: {(int(cp[\"center\"][1]) - int(center[1]))**2}')\n",
    "                #print(f'quadrado 3: {int(processed_contour_radius)**2}')\n",
    "                if (int(cp['center'][0]) - int(center[0]))**2 + (int(cp['center'][1]) - int(center[1]))**2 < processed_contour_radius**2: # check if center of circle is inside the contour\n",
    "                    circle_inside = True\n",
    "            else:\n",
    "                dist = cv2.pointPolygonTest(cp, center, True)\n",
    "            if dist > 0 or circle_inside: # center of the contour is inside a processed contour\n",
    "                #print(f'PRIMEIRA CONDIÇAO {(contour_radius >= 2/3 * processed_contour_radius and ((colourp == \"red\" and t == \"stop\") or (colour == \"red\" and tp != \"stop\")))}')\n",
    "                #print(f'SEGUNDA CONDIÇAO {(contour_radius >= processed_contour_radius and colour != \"blue\")}')\n",
    "                if (contour_radius >= 2/3 * processed_contour_radius and colour == \"red\" and not (t == \"stop\" or tp == \"stop\")) or (contour_radius >= processed_contour_radius and colour != \"blue\"): # the radius of the contour is bigger than the radius of the processed contour\n",
    "                    invalid_contours.append((tp, cp, colourp))\n",
    "                    append_contour = True\n",
    "            else:\n",
    "                processed_verified += 1\n",
    "\n",
    "\n",
    "        for i in invalid_contours:\n",
    "            processed_contours.remove(i)\n",
    "        if append_contour or (processed_verified == len(processed_contours)):\n",
    "            processed_contours.append((t, c, colour))\n",
    "\n",
    "\n",
    "\n",
    "    signs = []\n",
    "    stop_count = 0\n",
    "    rectangle_square = 0\n",
    "    triangle_count = 0\n",
    "    \n",
    "    for t, c, colour in processed_contours:\n",
    "        signs.append(t)\n",
    "        if t == \"stop\": \n",
    "            stop_count += 1\n",
    "        elif t == \"square\" or t == \"rectangle\":\n",
    "            rectangle_square += 1\n",
    "        elif t == \"triangle\":\n",
    "            triangle_count += 1\n",
    "            \n",
    "    if stop_count == 0:\n",
    "        stop_sign = os.path.join(\"./data/matching\", \"stop.png\")\n",
    "        matching(stop_sign, image_data.filename, image_data, \"STOP sign\")\n",
    "        \n",
    "    if rectangle_square == 0:\n",
    "        pedestrian1 = os.path.join(\"./data/matching\", \"pedestrian_left.png\")\n",
    "        matching(pedestrian1, image_data.filename, image_data, \"blue square\")\n",
    "        pedestrian2 = os.path.join(\"./data/matching\", \"pedestrian_right.png\")\n",
    "        matching(pedestrian2, image_data.filename, image_data, \"blue square\")\n",
    "        \n",
    "    if triangle_count == 0:\n",
    "        print(\"HHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHH\")\n",
    "        \n",
    "        triangle_sign = os.path.join(\"./data/matching\", \"bump.png\")\n",
    "        matching(triangle_sign, image_data.filename, image_data, \"red triangle\")\n",
    "        \n",
    "    for t, c, colour in processed_contours:\n",
    "        signs.append(t)\n",
    "        if t == \"circle\":\n",
    "            cv2.circle(image_data.image,(c['center']),c['radius'],(0,255,0),2) # draw the outer circle\n",
    "            cv2.circle(image_data.image,(c['center']),2,(0,0,255),3) # draw the center of the circle\n",
    "            cv2.putText(image_data.image, f\"{colour} circle\", (c['center'][0] - 35, c['center'][1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2) # write the shape\n",
    "        else:\n",
    "            if t == \"stop\": stop_count += 1\n",
    "            M = cv2.moments(c)\n",
    "            cX = int((M[\"m10\"] / (M[\"m00\"] + 1e-7))) #* ratio)\n",
    "            cY = int((M[\"m01\"] / (M[\"m00\"] + 1e-7))) #* ratio)\n",
    "            cv2.drawContours(image_data.image, [c], -1, (0, 255, 0), 2)\n",
    "            classification = f\"{colour} {t}\" if t != \"stop\" else \"stop sign\"\n",
    "            cv2.putText(image_data.image, classification, (cX - 35, cY - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "        \n",
    "    return signs, image_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will run our code, processing the request images.\n",
    "\n",
    "- Press any key to see the next image, if any\n",
    "- \n",
    "- Press the key `Esc` to exit the application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saturacao48.391725\n",
      "hue22.82315\n",
      "thresohold azul50.0\n",
      "Radius 6\n",
      "Radius 6\n",
      "HHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHH\n",
      "------\n",
      "['stop', 'circle', 'circle', 'stop', 'circle', 'circle']\n",
      "['stop']\n",
      "print56\n"
     ]
    }
   ],
   "source": [
    "def process_image(road_number):\n",
    "        filename = 'road' + str(road_number) + '.png'\n",
    "        image_data = Data(os.path.join(\"./data\", filename))\n",
    "        detected_signs, output_image = evaluate_image(image_data)\n",
    "        \n",
    "        with open('./data/annotations/road' + str(road_number) + '.xml', 'r') as f: data = f.read()\n",
    "        root = ET.fromstring(data)\n",
    "\n",
    "        real_signs = []\n",
    "        for content in root.findall('.//object/name'):\n",
    "                real_signs.append(content.text)\n",
    "\n",
    "        print('------')\n",
    "        print(detected_signs)\n",
    "        print(real_signs)\n",
    "\n",
    "        # Show the output image\n",
    "        if OUTPUT == \"WINDOW\":\n",
    "                cv2.imshow('Final Result', output_image.image)\n",
    "        else:\n",
    "                cv2.imwrite(f'output/{filename}', image_data.image)\n",
    "\n",
    "if not os.path.exists('./output'):\n",
    "        os.makedirs('./output')\n",
    "\n",
    "if FILENAME == \"ALL\":\n",
    "        for i in range(56, 876):\n",
    "                process_image(i) \n",
    "                print(\"print\" + str(i))\n",
    "                k = cv2.waitKey(0)   \n",
    "                cv2.destroyAllWindows()\n",
    "                if k == 27:\n",
    "                        break\n",
    "else:\n",
    "        process_image(FILENAME)\n",
    "\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ce41d2c9079f2c783da2c5a9243470309928341d0f7f9360b413f846a0d7760d"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
